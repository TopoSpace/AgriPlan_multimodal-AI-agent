# modules/llm_planner.py
# LLM Access (Synchronous + Streaming) - Full Available Version
# pip install openai==1.* tenacity pyyaml

from typing import Optional, List, Dict, Iterable
import os, yaml
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from openai import OpenAI
from openai.types.chat import (
    ChatCompletion,
    ChatCompletionChunk,
    ChatCompletionMessageParam,
)
from core.context import AgentContext
from modules.tool_dispatcher import (
    get_weather_forecast,
    get_weather_warnings,
    format_warning_text,
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. LLM(e.g. DeepSeek) Deployment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _load_llm_cfg() -> Dict[str, str]:
    with open("config/settings.yaml", "r", encoding="utf-8") as f:
        cfg = yaml.safe_load(f)
    llm_cfg = cfg.get("llm", {})
    return {
        "api_key": llm_cfg.get("apikey", os.getenv("DEEPSEEK_API_KEY", "")),
        "base_url": llm_cfg.get("api_host", "https://api.deepseek.com"),
        "model_chat": llm_cfg.get("model_chat", "deepseek-chat"),
        "model_reason": llm_cfg.get("model_reason", "deepseek-reasoner"),
    }


_LLM = _load_llm_cfg()
_client = OpenAI(api_key=_LLM["api_key"], base_url=_LLM["base_url"])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. universal package â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class LLMError(Exception):
    """Packaging Unified LLM Call Exception"""


@retry(
    reraise=True,
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=1, max=8),
    retry=retry_if_exception_type((LLMError, TimeoutError)),
)
def _chat_completion(
    messages: List[ChatCompletionMessageParam],
    model: str,
    temperature: float = 0.4,
) -> str:
    """Synchronized calls to LLM Chat"""
    try:
        resp: ChatCompletion = _client.chat.completions.create(  # type: ignore
            model=model,
            messages=messages,
            temperature=temperature,
            stream=False,
        )
        return (resp.choices[0].message.content or "").strip()
    except Exception as e:  # pragma: no cover
        raise LLMError(str(e))


def _stream_completion(
    messages: List[ChatCompletionMessageParam],
    model: str,
    temperature: float = 0.4,
) -> Iterable[str]:
    """æµå¼ç”Ÿæˆå™¨ï¼šyield delta.content"""
    try:
        stream = _client.chat.completions.create(  # type: ignore
            model=model,
            messages=messages,
            temperature=temperature,
            stream=True,
        )
        for chunk in stream:  # type: ignore # type: ChatCompletionChunk
            if chunk.choices and (delta := chunk.choices[0].delta.content):
                yield delta
    except Exception as e:  # pragma: no cover
        raise LLMError(str(e))


def _make_messages(sys_prompt: str, user_prompt: str) -> List[ChatCompletionMessageParam]:
    return [
        {"role": "system", "content": sys_prompt},
        {"role": "user", "content": user_prompt},
    ]


def call_llm(
    prompt: str,
    *,
    sys_prompt: str = "You are an expert agronomist assistant, answer clearly and concisely.",
    use_reasoner: bool = False,
    temperature: float = 0.4,
) -> str:
    model = _LLM["model_reason"] if use_reasoner else _LLM["model_chat"]
    return _chat_completion(_make_messages(sys_prompt, prompt), model, temperature)


def call_llm_stream(
    prompt: str,
    *,
    sys_prompt: str = "You are an expert agronomist assistant, answer clearly and concisely.",
    use_reasoner: bool = False,
    temperature: float = 0.4,
) -> Iterable[str]:
    model = _LLM["model_reason"] if use_reasoner else _LLM["model_chat"]
    return _stream_completion(_make_messages(sys_prompt, prompt), model, temperature)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. Prompt build tool â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _fmt_weather(wlist: List[Dict]) -> str:
    if not wlist:
        return "No weather data is available at this time.ï¼ˆæš‚æ— å¤©æ°”æ•°æ®ã€‚ï¼‰"
    return "\n".join(
        f"{w['date']}ï¼š{w.get('text_day','')}"
        f" {w.get('temp_min','?')}â€“{w.get('temp_max','?')}â„ƒ"
        f" precipitation (meteorology)ï¼ˆé™æ°´ï¼‰{w.get('precip','?')}mm humidityï¼ˆæ¹¿åº¦ï¼‰{w.get('humidity','?')}%"
        for w in wlist
    )


# ---------- PARTâ€‘1 ï¼šInitial planting plan ----------
def build_prompt_basic(ctx: AgentContext) -> str:
    lat = ctx.basic_info.location.lat if ctx.basic_info.location else None
    lon = ctx.basic_info.location.lon if ctx.basic_info.location else None

    weather7: List[Dict] = []
    warning_txt = "There are no weather warnings at this time.ï¼ˆæš‚æ— å¤©æ°”é¢„è­¦ã€‚ï¼‰"
    if lat is not None and lon is not None:
        weather7 = get_weather_forecast(lat, lon, 7)
        warnings = get_weather_warnings(lat, lon)
        warning_txt = format_warning_text(warnings)

    p: List[str] = [
        "You are an intelligent agricultural planning assistant with strong domain knowledge. Based on the following contextual information, please generate a practical, low-intervention, and climate-aware **overall planting plan**.ï¼ˆä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„å†œä¸šæ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·åŸºäºŽä»¥ä¸‹ä¿¡æ¯åˆ¶å®šä¸€ä»½ç§‘å­¦ã€çŽ°å®žã€é¿å…è¿‡åº¦äººå·¥å¹²é¢„çš„ {{ crop_name }} ç§æ¤æ•´ä½“è§„åˆ’æ–¹æ¡ˆã€‚ï¼‰\n",
        f"ã€Crop Typeï¼ˆä½œç‰©ç±»åž‹ï¼‰ã€‘{ctx.basic_info.crop_type}",
        f"ã€Planted Areaï¼ˆç§æ¤é¢ç§¯ï¼‰ã€‘{ctx.basic_info.area} acresï¼ˆäº©ï¼‰",
    ]

    soil = ctx.basic_info.soil
    if soil:
        if soil.pH:
            p.append(f"ã€Soil pHï¼ˆåœŸå£¤ pHï¼‰ã€‘{soil.pH}")
        if soil.organic_matter:
            p.append(f"ã€Soil Organic Matter Contentï¼ˆæœ‰æœºè´¨å«é‡ï¼‰ã€‘{soil.organic_matter}")
        if soil.notes:
            p.append(f"ã€Remarks on Soilï¼ˆåœŸå£¤å¤‡æ³¨ï¼‰ã€‘{soil.notes}")

    loc = ctx.basic_info.location
    if loc:
        if loc.name:
            p.append(f"ã€Name of Planting Plotï¼ˆåœ°å—åç§°ï¼‰ã€‘{loc.name}")
        if lat is not None and lon is not None:
            p.append(f"ã€Geographic Coordinatesï¼ˆåæ ‡ï¼‰ã€‘{lat:.6f}, {lon:.6f}")

    p.append("\nã€7-day weather forecastï¼ˆæœªæ¥ 7 å¤©å¤©æ°”ï¼‰ã€‘")
    p.append(_fmt_weather(weather7))
    p.append("\nã€Weather Warningï¼ˆå¤©æ°”é¢„è­¦ï¼‰ã€‘")
    p.append(warning_txt)
    p.append(
    "\nã€Output Requirements è¾“å‡ºè¦æ±‚ã€‘\n"
    "Please output in **English** with a clear and structured layout. Use bullet points or numbered lists where appropriate.\n\n"
    "è¯·ä½¿ç”¨ **è‹±æ–‡** è¾“å‡ºï¼Œè¯­è¨€è¦ä¸“ä¸šã€æ˜“äºŽå†œä¸šå·¥ä½œè€…ç†è§£ï¼Œæ ¼å¼æ¸…æ™°ï¼Œæœ‰æ¡ç†ï¼Œä¾¿äºŽå±•ç¤ºä¸Žæ‰§è¡Œã€‚è¯·æŒ‰å¦‚ä¸‹å†…å®¹ç”Ÿæˆï¼š\n\n"
    "1. âœ… **Crop Suitability Analysis ä½œç‰©é€‚å®œæ€§åˆ†æž**  \n"
    "   Evaluate whether the current environment supports planting, considering soil, climate, and history.\n\n"
    "2. ðŸ“… **Suggested Sowing Period æŽ¨èæ’­ç§æ—¶æ®µ**  \n"
    "   Specify a suitable sowing window with brief justification.\n\n"
    "3. ðŸŒ± **Planting Method ç§æ¤æ–¹å¼å»ºè®®**  \n"
    "   Recommend spacing, density, and auxiliary needs (e.g., mulch, greenhouse).\n\n"
    "4. ðŸ“ˆ **Key Growth Phase Management å…³é”®ç®¡ç†é˜¶æ®µ**  \n"
    "   Outline key agricultural activities at different stages (e.g., seedling, elongation, heading).\n\n"
    "5. âš ï¸ **Risks & Cautions é£Žé™©æç¤º**  \n"
    "   Gently point out any risks (e.g., extreme weather, poor drainage), avoiding exaggerated language.\n\n"
    "6. ðŸ› ï¸ **Intervention Recommendations äººå·¥å¹²é¢„å»ºè®®**  \n"
    "   ONLY suggest necessary manual actions (e.g., basic irrigation/fertilization). If no action is needed, clearly state \"No extra intervention is required at this stage.\"\n\n"
    "7. âœ… **Conclusion æ€»ç»“å»ºè®®**  \n"
    "   Conclude with a short summary suitable for implementation.\n\n"
    "Avoid unnecessary complexity. Do **not** recommend specific commercial products unless asked. Stay grounded in agricultural practice and weather constraints.\n"
)


    return "\n".join(p)


def generate_basic_planning(ctx: AgentContext) -> str:
    return call_llm(build_prompt_basic(ctx))


def generate_basic_planning_stream(ctx: AgentContext) -> Iterable[str]:
    return call_llm_stream(build_prompt_basic(ctx))


# ---------- PARTâ€‘2 ï¼ša day-by-day agricultural program ----------
def build_prompt_schedule(ctx: AgentContext, prev_summary: Optional[str] = None) -> str:
    p: List[str] = [
        "You are an expert agricultural grower, develop a day-by-day farm operation plan based on the following information:ï¼ˆä½ æ˜¯ä¸€ä½å†œä¸šç§æ¤ä¸“å®¶ï¼Œè¯·åŸºäºŽä»¥ä¸‹ä¿¡æ¯åˆ¶å®šé€æ—¥å†œäº‹æ“ä½œè®¡åˆ’ï¼šï¼‰\n",
        f"ã€Crop Typeï¼ˆä½œç‰©ç±»åž‹ï¼‰ã€‘{ctx.basic_info.crop_type}",
        f"ã€Planted Areaï¼ˆç§æ¤é¢ç§¯ï¼‰ã€‘{ctx.basic_info.area} acresï¼ˆäº©ï¼‰",
    ]

    if prev_summary:
        p.append("\nã€Planting Suitability Conclusionsï¼ˆç§æ¤é€‚å®œæ€§ç»“è®ºï¼‰ã€‘")
        p.append(prev_summary)

    # Targeted Planting Information
    g = ctx.planting_goal
    p.extend(
        [
            "\nã€Targeted Planting Informationï¼ˆç›®æ ‡ç§æ¤ä¿¡æ¯ï¼‰ã€‘",
            f"- Starting planting date:ï¼ˆèµ·å§‹ç§æ¤æ—¥æœŸï¼šï¼‰{g.start_date or '-'}",
            f"- Expected harvest date:ï¼ˆé¢„æœŸæ”¶èŽ·æ—¥æœŸï¼šï¼‰{g.end_date or '-'}",
            f"- Use of seedlings:ï¼ˆä½¿ç”¨è‹—ç§ï¼šï¼‰{g.seed_type or '-'}",
            f"- Use of fertilizers:ï¼ˆä½¿ç”¨è‚¥æ–™ï¼šï¼‰{g.fertilizer or '-'}",
            f"- Irrigation methods:ï¼ˆçŒæº‰æ–¹å¼ï¼šï¼‰{g.irrigation or '-'}",
            f"- Target yield:ï¼ˆç›®æ ‡äº§é‡ï¼šï¼‰{g.target_yield or '-'}",
            f"- Remarks/Notes:ï¼ˆå¤‡æ³¨ï¼šï¼‰{g.notes or '-'}",
        ]
    )

    # 30-day weather forecast
    lat = ctx.basic_info.location.lat if ctx.basic_info.location else None
    lon = ctx.basic_info.location.lon if ctx.basic_info.location else None
    weather30: List[Dict] = get_weather_forecast(lat, lon, 30) if (lat and lon) else []
    p.append("\nã€30-day weather forecastï¼ˆæœªæ¥ 30 å¤©å¤©æ°”ï¼‰ã€‘")
    p.append(_fmt_weather(weather30))

    p.append(
    "\nã€Output Requirements è¾“å‡ºè¦æ±‚ã€‘\n"
    "Please output in **English**, structured in a **day-by-day calendar style**, clearly listing operations for each day.\n\n"
    "è¯·ä½¿ç”¨è‹±æ–‡è¾“å‡ºï¼Œä»¥â€œé€æ—¥è®¡åˆ’å¡ç‰‡â€å½¢å¼è¾“å‡ºå†…å®¹ï¼Œæ¸…æ™°å‘ˆçŽ°æ¯æ—¥çš„å…³é”®å†œä¸šæ“ä½œã€‚æ¯æ—¥å»ºè®®åº”æ¶µç›–ä»¥ä¸‹æ–¹é¢ï¼š\n\n"
    "1. ðŸ“… **Date æ—¥æœŸ**  \n"
    "   Specify the operation date (e.g., July 25).\n\n"
    "2. ðŸŒ¤ï¸ **Weather Info å¤©æ°”ä¿¡æ¯**  \n"
    "   Briefly state the weather (already provided above, no need to infer).\n\n"
    "3. ðŸŒ¾ **Key Operation å†œä¸šæ“ä½œ**  \n"
    "   Suggest the main task for the day (e.g., soil preparation, irrigation, transplanting, fertilization).\n\n"
    "4. âš ï¸ **Caution æ³¨æ„äº‹é¡¹**  \n"
    "   Mention any potential concerns or observations based on weather or growth stage.\n\n"
    "5. ðŸ› ï¸ **Manual Intervention äººå·¥å¹²é¢„å»ºè®®**  \n"
    "   Only recommend necessary operations. If nothing is needed, write: \"No manual operation required today.\"\n\n"
    "Please keep each dayâ€™s description short and practical. Limit to one paragraph per day.\n\n"
    "Avoid generic language. Tailor the plan to current crop stage, soil and weather context. Do not recommend unnecessary tasks."
)

    return "\n".join(p)


def generate_daily_schedule(ctx: AgentContext, prev_summary: Optional[str]) -> str:
    return call_llm(build_prompt_schedule(ctx, prev_summary))


def generate_daily_schedule_stream(ctx: AgentContext, prev_summary: Optional[str]) -> Iterable[str]:
    return call_llm_stream(build_prompt_schedule(ctx, prev_summary))


# ---------- PARTâ€‘3 ï¼šrealtime_qa ----------
def build_prompt_realtime_qa(
    ctx: AgentContext,
    prev_summary: Optional[str] = None,
    prev_schedule: Optional[str] = None,
) -> str:
    qa = ctx.realtime_qa
    assert qa, "RealtimeQA should not be emptyï¼ˆä¸åº”ä¸ºç©ºï¼‰"

    p: List[str] = ["You are a farm advisor, answer the farmer's question in context:ï¼ˆä½ æ˜¯ä¸€ä½å†œäº‹é¡¾é—®ï¼Œè¯·ç»“åˆä¸Šä¸‹æ–‡å›žç­”å†œæ°‘é—®é¢˜ï¼šï¼‰\n"]

    if prev_summary:
        p.append("ã€Prior Suitability Conclusionsï¼ˆå‰æœŸé€‚å®œæ€§ç»“è®ºï¼‰ã€‘")
        p.append(prev_summary)
    if prev_schedule:
        p.append("\nã€Previous Daily Farming Programï¼ˆå‰æœŸé€æ—¥å†œäº‹è®¡åˆ’ï¼‰ã€‘")
        p.append(prev_schedule)

    p.append(f"\nã€Current Dateï¼ˆå½“å‰æ—¥æœŸï¼‰ã€‘{qa.date}")
    p.append(f"ã€Questions from farmersï¼ˆå†œæ°‘æé—®ï¼‰ã€‘{qa.question}")

    # å›¾åƒåˆ†æž
    if isinstance(qa.vision_analysis, dict) and qa.vision_analysis:
        v = qa.vision_analysis
        p.append("\nã€Image Recognition Resultsï¼ˆå›¾åƒè¯†åˆ«ç»“æžœï¼‰ã€‘")
        if v.get("image_summary"):
            p.append(f"- image summaryï¼ˆå›¾åƒæ‘˜è¦ï¼‰ï¼š{v['image_summary']}")
        if v.get("growth_analysis"):
            p.append(f"- growth analysisï¼ˆç”Ÿé•¿çŠ¶å†µï¼‰ï¼š{v['growth_analysis']}")
        if v.get("disease_detection"):
            p.append(f"- disease detectionï¼ˆç—…è™«å®³æ£€æµ‹ï¼‰ï¼š{v['disease_detection']}")

    # å½“å¤©å¤©æ°”
    lat = ctx.basic_info.location.lat if ctx.basic_info.location else None
    lon = ctx.basic_info.location.lon if ctx.basic_info.location else None
    today_weather = ""
    warn_txt = "There are no weather warnings at this time.ï¼ˆæš‚æ— å¤©æ°”é¢„è­¦ã€‚ï¼‰"
    if lat is not None and lon is not None:
        weather7 = get_weather_forecast(lat, lon, 7)
        today_weather = _fmt_weather(weather7[:1])
        warn_txt = format_warning_text(get_weather_warnings(lat, lon))

    p.append("\nã€Today's weatherï¼ˆå½“å¤©å¤©æ°”ï¼‰ã€‘")
    p.append(today_weather or "No weather data availableï¼ˆæš‚æ— å¤©æ°”æ•°æ®ï¼‰")
    p.append("\nã€weather warningï¼ˆå¤©æ°”é¢„è­¦ï¼‰ã€‘")
    p.append(warn_txt)

    p.append(
    "\nã€Output Requirements è¾“å‡ºè¦æ±‚ã€‘\n"
    "You are acting as a **smart agricultural assistant** that provides helpful, precise, and grounded responses to farmersâ€™ questions in real-time.\n\n"
    "ä½ çŽ°åœ¨æ˜¯ä¸€ä¸ªå†œä¸šæ™ºèƒ½åŠ©æ‰‹ï¼Œéœ€è¦å®žæ—¶å›žç­”å†œæˆ·æå‡ºçš„å…·ä½“é—®é¢˜ã€‚è¯·ç¡®ä¿ï¼š\n\n"
    "1. ðŸ¤– **Grounded Reasoning åŸºäºŽä¸Šä¸‹æ–‡æŽ¨ç†**  \n"
    "   Always refer to the known planting context (crop, soil, weather, prior plans). Do not fabricate.\n\n"
    "2. ðŸ“¸ **Image Understanding å›¾åƒç†è§£ï¼ˆå¦‚æœ‰ï¼‰**  \n"
    "   If an image is uploaded, analyze crop condition from the photo (growth, diseases, pests) and provide insights accordingly.\n\n"
    "3. ðŸ§‘â€ðŸŒ¾ **Farmer-Friendly Language è¯­è¨€å‹å¥½**  \n"
    "   Keep your explanation accurate yet easy to follow for agricultural workers.\n\n"
    "4. âš ï¸ **Avoid Over-intervention é¿å…è¿‡åº¦å¹²é¢„**  \n"
    "   Only recommend manual intervention if absolutely necessary. Otherwise, say \"No intervention needed for now.\"\n\n"
    "5. ðŸŒ± **Link to Current Stage ä¸Žå½“å‰é˜¶æ®µè”åŠ¨**  \n"
    "   Make sure your suggestions are consistent with the current stage of growth and prior planning.\n\n"
    "ã€If Image is Provided å›¾ç‰‡åˆ†æžè¦æ±‚ã€‘\n"
    "Please include a section:\n"
    "**ðŸ” Image Diagnosis å›¾åƒè¯Šæ–­**:\n"
    "- Describe crop growth visually.\n"
    "- Identify possible symptoms or issues.\n"
    "- Suggest action or note \"No visible issue.\"\n\n"
    "ã€General Rule é€šç”¨è§„åˆ™ã€‘\n"
    "- Avoid generic or copy-paste responses.\n"
    "- Answer in **English** with professional and structured format.\n"
    "- Limit each reply to 2-3 well-written paragraphs or bullet points.\n"
)

    return "\n".join(p)


def generate_realtime_answer(
    ctx: AgentContext,
    prev_summary: Optional[str] = None,
    prev_schedule: Optional[str] = None,
) -> str:
    return call_llm(build_prompt_realtime_qa(ctx, prev_summary, prev_schedule), temperature=0.5)


def generate_realtime_answer_stream(
    ctx: AgentContext,
    prev_summary: Optional[str] = None,
    prev_schedule: Optional[str] = None,
) -> Iterable[str]:
    return call_llm_stream(build_prompt_realtime_qa(ctx, prev_summary, prev_schedule), temperature=0.5)
